#%%---------------------Entrainement manuel-------------------------------------------
import serial
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import csv
import os

# -------- CONFIG --------
PORT_SERIE = 'COM3'  # adapte ici
BAUDRATE = 9600
NOM_FICHIER_CSV = "donnees_manche.csv"

def charger_donnees_csv(nom_fichier):
    donnees = []
    labels = []
    if os.path.exists(nom_fichier):
        with open(nom_fichier, newline='') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) != 7:
                    continue
                try:
                    capteurs = list(map(float, row[:6]))
                    label = int(row[6])
                    donnees.append(capteurs)
                    labels.append(label)
                except:
                    continue
    return donnees, labels

def sauvegarder_donnees_csv(nom_fichier, donnees, labels):
    with open(nom_fichier, 'w', newline='') as f:
        writer = csv.writer(f)
        for capteurs, label in zip(donnees, labels):
            writer.writerow(capteurs + [label])

def collecte_donnees(port, baudrate, donnees_existantes, labels_existants):
    ser = serial.Serial(port, baudrate)
    print("Port s√©rie ouvert. Ctrl+C pour arr√™ter la collecte.")
    donnees = donnees_existantes.copy()
    labels = labels_existants.copy()

    # On ouvre en mode ajout pour sauvegarder les nouvelles donn√©es au fur et √† mesure
    f_csv = open(NOM_FICHIER_CSV, 'a', newline='')
    writer = csv.writer(f_csv)

    try:
        while True:
            ligne = ser.readline().decode(errors='ignore').strip()
            valeurs = ligne.split(",")
            if len(valeurs) == 6:
                try:
                    capteurs = list(map(float, valeurs))
                except:
                    print("Erreur de conversion :", valeurs)
                    continue
                print(f"Capteurs re√ßus : {capteurs}")
                pos = input("Position (0 ou 1) ? ")
                if pos not in ['0', '1']:
                    print("Position invalide, r√©essaie.")
                    continue
                label = int(pos)
                donnees.append(capteurs)
                labels.append(label)
                writer.writerow(capteurs + [label])
                f_csv.flush()
    except KeyboardInterrupt:
        print("\nCollecte termin√©e.")
    ser.close()
    f_csv.close()
    return donnees, labels

def entrainer_modele(donnees, labels):
    from collections import Counter
    print(f"Nombre total d'exemples : {len(labels)}")
    print(f"R√©partition des classes : {Counter(labels)}")

    X = np.array(donnees)
    y = np.array(labels)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    model = MLPClassifier(hidden_layer_sizes=(16,16), activation='relu', max_iter=1000)
    print("Entra√Ænement du mod√®le...")
    model.fit(X_train, y_train)

    score = model.score(X_test, y_test)
    print(f"Pr√©cision sur le test : {score*100:.2f}%")

    joblib.dump(model, "mlp_manche_model.joblib")
    joblib.dump(scaler, "mlp_manche_scaler.joblib")
    print("Mod√®le et scaler sauvegard√©s.")

    return model, scaler

def prediction_realtime(port, baudrate):
    clf = joblib.load("mlp_manche_model.joblib")
    sc = joblib.load("mlp_manche_scaler.joblib")

    ser = serial.Serial(port, baudrate)
    print("Mode pr√©diction en temps r√©el. Ctrl+C pour quitter.")

    try:
        while True:
            ligne = ser.readline().decode(errors='ignore').strip()
            valeurs = ligne.split(",")
            if len(valeurs) == 6:
                try:
                    capteurs = list(map(float, valeurs))
                except:
                    continue
                X_input = np.array(capteurs).reshape(1, -1)
                X_scaled = sc.transform(X_input)
                pred = clf.predict(X_scaled)
                print(f"Capteurs: {capteurs} --> Pr√©diction position: {pred[0]}")
    except KeyboardInterrupt:
        print("\nArr√™t du mode pr√©diction.")
    ser.close()

if __name__ == "__main__":
    print("=== Gestion des donn√©es du manche ===")
    if os.path.exists(NOM_FICHIER_CSV):
        choix = input(f"Fichier '{NOM_FICHIER_CSV}' existe. Souhaites-tu le r√©initialiser ? (o/n) : ")
        if choix.lower() == 'o':
            os.remove(NOM_FICHIER_CSV)
            print("Fichier supprim√©. Nouvelle collecte commencera sur base vide.")

    donnees, labels = charger_donnees_csv(NOM_FICHIER_CSV)
    print(f"Donn√©es charg√©es : {len(labels)} exemples.")

    donnees, labels = collecte_donnees(PORT_SERIE, BAUDRATE, donnees, labels)

    model, scaler = entrainer_modele(donnees, labels)

    # prediction_realtime(PORT_SERIE, BAUDRATE)

#%%---------------------------Entrainement triple------------------------------
import serial
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib
import csv
import os
from collections import Counter

# ====== PARAM√àTRES ======
PORT_SERIE = 'COM3'  # adapte ton port
BAUDRATE = 9600
NOM_FICHIER_CSV = "donnees_manche.csv"
CLASSES = [0, 1, 2]

def charger_donnees_csv(nom_fichier):
    donnees, labels = [], []
    if os.path.exists(nom_fichier):
        with open(nom_fichier, newline='') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) == 7:
                    try:
                        capteurs = list(map(float, row[:6]))
                        label = int(row[6])
                        donnees.append(capteurs)
                        labels.append(label)
                    except:
                        continue
    return donnees, labels

def collecte_par_bloc(port, baudrate, donnees_existantes, labels_existants):
    ser = serial.Serial(port, baudrate)
    print("Port s√©rie ouvert.")

    donnees = donnees_existantes.copy()
    labels = labels_existants.copy()

    with open(NOM_FICHIER_CSV, 'a', newline='') as f_csv:
        writer = csv.writer(f_csv)

        for position in CLASSES:
            input(f"\n‚ñ∂ Appuie sur [Entr√©e] pour commencer la collecte pour la position {position}...")
            print(f"‚û° Collecte de la position {position}. Appuie sur [Entr√©e] pour passer √† la suivante...")
            while True:
                if os.name == 'nt':
                    import msvcrt
                    if msvcrt.kbhit() and msvcrt.getwch() == '\r':
                        break
                else:
                    import sys, select
                    if select.select([sys.stdin], [], [], 0)[0]:
                        sys.stdin.readline()
                        break

                ligne = ser.readline().decode(errors='ignore').strip()
                valeurs = ligne.split(",")
                if len(valeurs) == 6:
                    try:
                        capteurs = list(map(float, valeurs))
                        donnees.append(capteurs)
                        labels.append(position)
                        writer.writerow(capteurs + [position])
                        f_csv.flush()
                        print(f"Capteurs : {capteurs} --> Position {position}")
                    except:
                        continue

    ser.close()
    print("‚úÖ Collecte termin√©e.")
    return donnees, labels

def entrainer_modele(donnees, labels):
    print(f"\nüìä Donn√©es totales : {len(labels)}")
    print("R√©partition par classe :", dict(Counter(labels)))

    X = np.array(donnees)
    y = np.array(labels)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)

    model = MLPClassifier(hidden_layer_sizes=(32,32), activation='relu', max_iter=1000)
    print("üß† Entra√Ænement du mod√®le...")
    model.fit(X_train, y_train)

    score = model.score(X_test, y_test)
    print(f"‚úÖ Pr√©cision sur le test : {score*100:.2f}%")

    joblib.dump(model, "mlp_manche_model.joblib")
    joblib.dump(scaler, "mlp_manche_scaler.joblib")
    print("üì¶ Mod√®le et scaler sauvegard√©s.")

def prediction_realtime(port, baudrate):
    clf = joblib.load("mlp_manche_model.joblib")
    sc = joblib.load("mlp_manche_scaler.joblib")

    ser = serial.Serial(port, baudrate)
    print("üü¢ Mode pr√©diction en temps r√©el (Ctrl+C pour quitter)")

    try:
        while True:
            ligne = ser.readline().decode(errors='ignore').strip()
            valeurs = ligne.split(",")
            if len(valeurs) == 6:
                try:
                    capteurs = list(map(float, valeurs))
                    X_input = np.array(capteurs).reshape(1, -1)
                    X_scaled = sc.transform(X_input)
                    pred = clf.predict(X_scaled)
                    print(f"Capteurs : {capteurs} --> Pr√©diction : {pred[0]}")
                except:
                    continue
    except KeyboardInterrupt:
        print("\nüî¥ Arr√™t du mode pr√©diction.")
    ser.close()

# ========== LANCEMENT ==========
if __name__ == "__main__":
    print("=== R√©seau de Neurones ‚Äì 3 Positions ===")

    if os.path.exists(NOM_FICHIER_CSV):
        choix = input(f"Le fichier '{NOM_FICHIER_CSV}' existe. R√©initialiser ? (o/n) : ")
        if choix.lower() == 'o':
            os.remove(NOM_FICHIER_CSV)
            print("üìÅ Fichier r√©initialis√©.")

    donnees, labels = charger_donnees_csv(NOM_FICHIER_CSV)
    print(f"Donn√©es existantes charg√©es : {len(labels)} exemples")

    donnees, labels = collecte_par_bloc(PORT_SERIE, BAUDRATE, donnees, labels)

    entrainer_modele(donnees, labels)

    # D√©commente la ligne ci-dessous si tu veux activer la pr√©diction en live :
    # prediction_realtime(PORT_SERIE, BAUDRATE)

#%%---------------------V√©rification des valeurs-------------------------------
import csv
from collections import Counter

NOM_FICHIER_CSV = "donnees_manche.csv"

def compter_classes(nom_fichier):
    labels = []
    with open(nom_fichier, newline='') as f:
        reader = csv.reader(f)
        for row in reader:
            if len(row) != 7:
                continue
            try:
                label = int(row[6])
                labels.append(label)
            except:
                continue
    compteur = Counter(labels)
    for classe, nb in compteur.items():
        print(f"Classe {classe} : {nb} exemples")

if __name__ == "__main__":
    compter_classes(NOM_FICHIER_CSV)
